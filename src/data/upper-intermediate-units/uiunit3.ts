import { Unit } from "../elementary";
export const uiunit3: Unit = {
  id: 3, title: "äººå·¥æ™ºæ…§èˆ‡å€«ç†", icon: "ğŸ¤–", color: "#6366f1",
  vocab: [
    { en: "artificial intelligence", zh: "äººå·¥æ™ºæ…§", pos: "n.", ex: "Artificial intelligence is transforming every industry." },{ en: "algorithm", zh: "æ¼”ç®—æ³•", pos: "n.", ex: "The algorithm determines what content you see online." },{ en: "automation", zh: "è‡ªå‹•åŒ–", pos: "n.", ex: "Automation has replaced many manufacturing jobs." },{ en: "neural network", zh: "ç¥ç¶“ç¶²è·¯", pos: "n.", ex: "Neural networks are modeled after the human brain." },{ en: "machine learning", zh: "æ©Ÿå™¨å­¸ç¿’", pos: "n.", ex: "Machine learning allows computers to improve from experience." },{ en: "bias", zh: "åè¦‹", pos: "n.", ex: "AI systems can perpetuate human biases." },{ en: "surveillance", zh: "ç›£æ§", pos: "n.", ex: "Mass surveillance raises serious privacy concerns." },{ en: "autonomous", zh: "è‡ªä¸»çš„", pos: "adj.", ex: "Autonomous vehicles may reduce traffic accidents." },{ en: "accountability", zh: "å•è²¬", pos: "n.", ex: "Who bears accountability when an AI makes a mistake?" },{ en: "transparency", zh: "é€æ˜åº¦", pos: "n.", ex: "AI decision-making should be transparent." },
    { en: "deep learning", zh: "æ·±åº¦å­¸ç¿’", pos: "n.", ex: "Deep learning has achieved remarkable results in image recognition." },{ en: "data mining", zh: "è³‡æ–™æ¢å‹˜", pos: "n.", ex: "Data mining reveals hidden patterns in large datasets." },{ en: "facial recognition", zh: "è‡‰éƒ¨è¾¨è­˜", pos: "n.", ex: "Facial recognition technology is used in airports." },{ en: "cybersecurity", zh: "ç¶²è·¯å®‰å…¨", pos: "n.", ex: "Cybersecurity threats are increasing every year." },{ en: "encryption", zh: "åŠ å¯†", pos: "n.", ex: "End-to-end encryption protects your messages." },{ en: "blockchain", zh: "å€å¡Šéˆ", pos: "n.", ex: "Blockchain technology ensures data integrity." },{ en: "virtual reality", zh: "è™›æ“¬å¯¦å¢ƒ", pos: "n.", ex: "Virtual reality is used for medical training." },{ en: "augmented reality", zh: "æ“´å¢å¯¦å¢ƒ", pos: "n.", ex: "Augmented reality overlays digital information on the real world." },{ en: "robotics", zh: "æ©Ÿå™¨äººå­¸", pos: "n.", ex: "Advances in robotics have transformed manufacturing." },{ en: "singularity", zh: "ç§‘æŠ€å¥‡é»", pos: "n.", ex: "Some predict the technological singularity within this century." },
    { en: "ethical", zh: "åˆä¹å€«ç†çš„", pos: "adj.", ex: "Is it ethical to use AI for hiring decisions?" },{ en: "regulate", zh: "è¦ç¯„", pos: "v.", ex: "Governments are struggling to regulate AI." },{ en: "consent", zh: "åŒæ„", pos: "n.", ex: "Users should give informed consent for data collection." },{ en: "anonymize", zh: "åŒ¿ååŒ–", pos: "v.", ex: "Personal data should be anonymized." },{ en: "disinformation", zh: "å‡è¨Šæ¯", pos: "n.", ex: "AI-generated disinformation is a growing threat." },{ en: "deepfake", zh: "æ·±å½æŠ€è¡“", pos: "n.", ex: "Deepfakes can create convincing but fake videos." },{ en: "obsolete", zh: "éæ™‚çš„", pos: "adj.", ex: "Many jobs may become obsolete due to AI." },{ en: "disruptive", zh: "é¡›è¦†æ€§çš„", pos: "adj.", ex: "AI is the most disruptive technology of our time." },{ en: "unprecedented", zh: "å‰æ‰€æœªæœ‰çš„", pos: "adj.", ex: "We face unprecedented technological challenges." },{ en: "mitigate", zh: "æ¸›è¼•", pos: "v.", ex: "Steps must be taken to mitigate the risks of AI." },
    { en: "sentiment analysis", zh: "æƒ…æ„Ÿåˆ†æ", pos: "n.", ex: "Sentiment analysis determines opinions from text." },{ en: "predictive", zh: "é æ¸¬æ€§çš„", pos: "adj.", ex: "Predictive policing uses data to forecast crime." },{ en: "optimize", zh: "æœ€ä½³åŒ–", pos: "v.", ex: "AI can optimize supply chain operations." },{ en: "simulate", zh: "æ¨¡æ“¬", pos: "v.", ex: "Computers can simulate complex systems." },{ en: "generative", zh: "ç”Ÿæˆå¼çš„", pos: "adj.", ex: "Generative AI can produce text, images, and music." },{ en: "hallucination", zh: "å¹»è¦º(AI)", pos: "n.", ex: "AI hallucination occurs when the model generates false information." },{ en: "alignment", zh: "å°é½Š", pos: "n.", ex: "AI alignment ensures AI goals match human values." },{ en: "superintelligence", zh: "è¶…ç´šæ™ºæ…§", pos: "n.", ex: "Superintelligence could surpass all human abilities." },{ en: "existential risk", zh: "å­˜äº¡é¢¨éšª", pos: "n.", ex: "Some view unaligned AI as an existential risk." },{ en: "augment", zh: "å¢å¼·", pos: "v.", ex: "AI should augment human capabilities, not replace them." },
    { en: "neural", zh: "ç¥ç¶“çš„", pos: "adj.", ex: "Neural interfaces connect the brain to computers." },{ en: "cognitive", zh: "èªçŸ¥çš„", pos: "adj.", ex: "AI is advancing in cognitive tasks." },{ en: "scalable", zh: "å¯æ“´å±•çš„", pos: "adj.", ex: "The solution must be scalable to millions of users." },{ en: "interoperable", zh: "å¯äº’é€šçš„", pos: "adj.", ex: "Systems need to be interoperable." },{ en: "deploy", zh: "éƒ¨ç½²", pos: "v.", ex: "The company deployed AI across its operations." },{ en: "iteration", zh: "è¿­ä»£", pos: "n.", ex: "Each iteration improves the model's performance." },{ en: "benchmark", zh: "åŸºæº–", pos: "n.", ex: "The new model set a benchmark for performance." },{ en: "parameter", zh: "åƒæ•¸", pos: "n.", ex: "Large language models have billions of parameters." },{ en: "inference", zh: "æ¨è«–", pos: "n.", ex: "The model makes inferences based on patterns." },{ en: "proprietary", zh: "å°ˆæœ‰çš„", pos: "adj.", ex: "The algorithm is proprietary technology." },
    { en: "open source", zh: "é–‹æºçš„", pos: "adj.", ex: "Open source AI promotes collaboration." },{ en: "intellectual property", zh: "æ™ºæ…§è²¡ç”¢æ¬Š", pos: "n.", ex: "AI-generated art raises intellectual property questions." },{ en: "liability", zh: "è²¬ä»»", pos: "n.", ex: "Who bears liability for AI errors?" },{ en: "legislation", zh: "ç«‹æ³•", pos: "n.", ex: "New legislation is needed for AI governance." },{ en: "compliance", zh: "åˆè¦", pos: "n.", ex: "Companies must ensure AI compliance with regulations." },{ en: "stakeholder", zh: "åˆ©å®³é—œä¿‚äºº", pos: "n.", ex: "All stakeholders should be consulted in AI policy." },{ en: "workforce", zh: "å‹å‹•åŠ›", pos: "n.", ex: "AI will transform the global workforce." },{ en: "reskill", zh: "é‡æ–°åŸ¹è¨“æŠ€èƒ½", pos: "v.", ex: "Workers must reskill for the AI economy." },{ en: "paradigm shift", zh: "å…¸ç¯„è½‰ç§»", pos: "n.", ex: "AI represents a paradigm shift in technology." },{ en: "ubiquitous", zh: "ç„¡æ‰€ä¸åœ¨çš„", pos: "adj.", ex: "AI is becoming ubiquitous in daily life." },
    { en: "neural network", zh: "ç¥ç¶“ç¶²è·¯", pos: "n.", ex: "Neural networks are inspired by the human brain." },
    { en: "deep learning", zh: "æ·±åº¦å­¸ç¿’", pos: "n.", ex: "Deep learning has achieved breakthroughs in image recognition." },
    { en: "natural language processing", zh: "è‡ªç„¶èªè¨€è™•ç†", pos: "n.", ex: "NLP allows computers to understand human language." },
    { en: "generative AI", zh: "ç”Ÿæˆå¼AI", pos: "n.", ex: "Generative AI can create text, images, and music." },
    { en: "machine learning", zh: "æ©Ÿå™¨å­¸ç¿’", pos: "n.", ex: "Machine learning algorithms improve with more data." },
    { en: "algorithmic bias", zh: "æ¼”ç®—æ³•åè¦‹", pos: "n.", ex: "Algorithmic bias can lead to discriminatory outcomes." },
    { en: "autonomous", zh: "è‡ªä¸»çš„", pos: "adj.", ex: "Autonomous systems operate without human intervention." },
    { en: "transparency", zh: "é€æ˜åº¦", pos: "n.", ex: "AI systems need greater transparency in decision-making." },
    { en: "accountability", zh: "å•è²¬æ€§", pos: "n.", ex: "Who bears accountability when an AI system fails?" },
    { en: "surveillance", zh: "ç›£æ§", pos: "n.", ex: "Facial recognition enables mass surveillance." },
    { en: "sentiment analysis", zh: "æƒ…æ„Ÿåˆ†æ", pos: "n.", ex: "Sentiment analysis detects emotions in text." },
    { en: "data mining", zh: "è³‡æ–™æ¢å‹˜", pos: "n.", ex: "Data mining extracts patterns from large datasets." },
    { en: "predictive model", zh: "é æ¸¬æ¨¡å‹", pos: "n.", ex: "Predictive models forecast future trends." },
    { en: "reinforcement learning", zh: "å¼·åŒ–å­¸ç¿’", pos: "n.", ex: "Reinforcement learning trains AI through rewards and penalties." },
    { en: "hallucination", zh: "å¹»è¦º", pos: "n.", ex: "AI hallucination occurs when models generate false information." },
    { en: "explainability", zh: "å¯è§£é‡‹æ€§", pos: "n.", ex: "Explainability is crucial for trust in AI systems." },
    { en: "chatbot", zh: "èŠå¤©æ©Ÿå™¨äºº", pos: "n.", ex: "The chatbot handles thousands of customer inquiries daily." },
    { en: "automation", zh: "è‡ªå‹•åŒ–", pos: "n.", ex: "Automation threatens certain types of jobs." },
    { en: "superintelligence", zh: "è¶…ç´šæ™ºæ…§", pos: "n.", ex: "Some worry about the risks of superintelligence." },
    { en: "deepfake", zh: "æ·±å½æŠ€è¡“", pos: "n.", ex: "Deepfakes use AI to create realistic fake videos." },
    { en: "consent", zh: "åŒæ„", pos: "n.", ex: "Users should give informed consent before data collection." },
    { en: "intellectual property", zh: "æ™ºæ…§è²¡ç”¢", pos: "n.", ex: "AI-generated art raises intellectual property questions." },
    { en: "disinformation", zh: "è™›å‡è¨Šæ¯", pos: "n.", ex: "AI can be used to spread disinformation at scale." },
    { en: "regulation", zh: "æ³•è¦", pos: "n.", ex: "Governments are developing AI regulation frameworks." },
    { en: "digital divide", zh: "æ•¸ä½è½å·®", pos: "n.", ex: "The digital divide may widen as AI advances." },
    { en: "synthetic data", zh: "åˆæˆè³‡æ–™", pos: "n.", ex: "Synthetic data protects privacy while training models." },
    { en: "computational", zh: "é‹ç®—çš„", pos: "adj.", ex: "Training large models requires enormous computational power." },
    { en: "inference", zh: "æ¨ç†", pos: "n.", ex: "AI inference runs the trained model on new data." },
    { en: "benchmark", zh: "åŸºæº–æ¸¬è©¦", pos: "n.", ex: "New benchmarks measure AI capabilities more accurately." },
    { en: "open source", zh: "é–‹æº", pos: "adj.", ex: "Open source AI models promote collaboration." },
    { en: "parameter", zh: "åƒæ•¸", pos: "n.", ex: "Large language models have billions of parameters." },
    { en: "fine-tuning", zh: "å¾®èª¿", pos: "n.", ex: "Fine-tuning adapts a general model for specific tasks." },
    { en: "prompt engineering", zh: "æç¤ºå·¥ç¨‹", pos: "n.", ex: "Prompt engineering helps get better results from AI." },
    { en: "embodied AI", zh: "å…·èº«AI", pos: "n.", ex: "Embodied AI integrates intelligence with physical robots." },
    { en: "federated learning", zh: "è¯é‚¦å­¸ç¿’", pos: "n.", ex: "Federated learning trains models without sharing raw data." },
    { en: "adversarial attack", zh: "å°æŠ—æ”»æ“Š", pos: "n.", ex: "Adversarial attacks exploit vulnerabilities in AI systems." },
    { en: "robotic process automation", zh: "æ©Ÿå™¨äººæµç¨‹è‡ªå‹•åŒ–", pos: "n.", ex: "RPA automates repetitive business tasks." },
    { en: "digital twin", zh: "æ•¸ä½åˆ†èº«", pos: "n.", ex: "Digital twins simulate real-world objects and systems." },
    { en: "edge computing", zh: "é‚Šç·£é‹ç®—", pos: "n.", ex: "Edge computing processes data closer to where it's generated." },
    { en: "singularity", zh: "å¥‡é»", pos: "n.", ex: "The technological singularity is a hypothetical future event." },
  
    { en: "neural network", zh: "ç¥ç¶“ç¶²è·¯", pos: "n.", ex: "Neural networks are inspired by the human brain." },{ en: "deep learning", zh: "æ·±åº¦å­¸ç¿’", pos: "n.", ex: "Deep learning powers many AI applications." },{ en: "machine learning", zh: "æ©Ÿå™¨å­¸ç¿’", pos: "n.", ex: "Machine learning enables computers to learn from data." },{ en: "natural language processing", zh: "è‡ªç„¶èªè¨€è™•ç†", pos: "n.", ex: "Natural language processing helps computers understand text." },{ en: "computer vision", zh: "é›»è…¦è¦–è¦º", pos: "n.", ex: "Computer vision enables machines to interpret images." },{ en: "reinforcement learning", zh: "å¼·åŒ–å­¸ç¿’", pos: "n.", ex: "Reinforcement learning trains agents through rewards." },{ en: "supervised learning", zh: "ç›£ç£å¼å­¸ç¿’", pos: "n.", ex: "Supervised learning uses labeled data for training." },{ en: "unsupervised learning", zh: "éç›£ç£å¼å­¸ç¿’", pos: "n.", ex: "Unsupervised learning finds patterns in unlabeled data." },{ en: "generative AI", zh: "ç”Ÿæˆå¼AI", pos: "n.", ex: "Generative AI creates text, images, and music." },{ en: "large language model", zh: "å¤§å‹èªè¨€æ¨¡å‹", pos: "n.", ex: "Large language models can generate human-like text." },
    { en: "algorithmic bias", zh: "æ¼”ç®—æ³•åè¦‹", pos: "n.", ex: "Algorithmic bias can perpetuate discrimination." },{ en: "explainability", zh: "å¯è§£é‡‹æ€§", pos: "n.", ex: "AI explainability helps users understand decisions." },{ en: "transparency", zh: "é€æ˜åº¦", pos: "n.", ex: "Transparency in AI systems builds public trust." },{ en: "accountability", zh: "å•è²¬åˆ¶", pos: "n.", ex: "Who bears accountability when AI makes errors?" },{ en: "autonomous", zh: "è‡ªä¸»çš„", pos: "adj.", ex: "Autonomous vehicles raise safety concerns." },{ en: "surveillance", zh: "ç›£æ§", pos: "n.", ex: "AI surveillance raises privacy concerns." },{ en: "facial recognition", zh: "è‡‰éƒ¨è¾¨è­˜", pos: "n.", ex: "Facial recognition technology is controversial." },{ en: "deepfake", zh: "æ·±å½æŠ€è¡“", pos: "n.", ex: "Deepfakes can spread misinformation." },{ en: "data mining", zh: "è³‡æ–™æ¢å‹˜", pos: "n.", ex: "Data mining extracts patterns from large datasets." },{ en: "predictive analytics", zh: "é æ¸¬åˆ†æ", pos: "n.", ex: "Predictive analytics forecasts future trends." },
    { en: "automation", zh: "è‡ªå‹•åŒ–", pos: "n.", ex: "Automation may displace many workers." },{ en: "job displacement", zh: "å·¥ä½œå–ä»£", pos: "n.", ex: "AI-driven job displacement concerns economists." },{ en: "singularity", zh: "ç§‘æŠ€å¥‡é»", pos: "n.", ex: "The singularity refers to AI surpassing human intelligence." },{ en: "superintelligence", zh: "è¶…ç´šæ™ºæ…§", pos: "n.", ex: "Superintelligence is a theoretical concept in AI." },{ en: "sentience", zh: "çŸ¥è¦ºèƒ½åŠ›", pos: "n.", ex: "Can machines ever achieve sentience?" },{ en: "Turing test", zh: "åœ–éˆæ¸¬è©¦", pos: "n.", ex: "The Turing test evaluates machine intelligence." },{ en: "hallucination", zh: "å¹»è¦ºï¼ˆAIï¼‰", pos: "n.", ex: "AI hallucinations produce false information." },{ en: "prompt engineering", zh: "æç¤ºå·¥ç¨‹", pos: "n.", ex: "Prompt engineering improves AI output quality." },{ en: "fine-tuning", zh: "å¾®èª¿", pos: "n.", ex: "Fine-tuning adapts models to specific tasks." },{ en: "training data", zh: "è¨“ç·´è³‡æ–™", pos: "n.", ex: "The quality of training data affects AI performance." },
    { en: "overfitting", zh: "éåº¦æ“¬åˆ", pos: "n.", ex: "Overfitting makes models perform poorly on new data." },{ en: "parameter", zh: "åƒæ•¸", pos: "n.", ex: "Large models have billions of parameters." },{ en: "inference", zh: "æ¨è«–", pos: "n.", ex: "AI inference generates predictions from learned patterns." },{ en: "edge computing", zh: "é‚Šç·£é‹ç®—", pos: "n.", ex: "Edge computing brings AI processing closer to users." },{ en: "cloud AI", zh: "é›²ç«¯AI", pos: "n.", ex: "Cloud AI provides scalable computing power." },{ en: "robotics", zh: "æ©Ÿå™¨äººå­¸", pos: "n.", ex: "Robotics combines engineering and AI." },{ en: "chatbot", zh: "èŠå¤©æ©Ÿå™¨äºº", pos: "n.", ex: "Chatbots handle customer service inquiries." },{ en: "recommendation system", zh: "æ¨è–¦ç³»çµ±", pos: "n.", ex: "Recommendation systems personalize content." },{ en: "natural language generation", zh: "è‡ªç„¶èªè¨€ç”Ÿæˆ", pos: "n.", ex: "Natural language generation creates readable text." },{ en: "speech recognition", zh: "èªéŸ³è¾¨è­˜", pos: "n.", ex: "Speech recognition powers virtual assistants." },
    { en: "ethical AI", zh: "å€«ç†AI", pos: "n.", ex: "Ethical AI prioritizes fairness and transparency." },{ en: "responsible AI", zh: "è² è²¬ä»»AI", pos: "n.", ex: "Responsible AI considers societal impact." },{ en: "AI governance", zh: "AIæ²»ç†", pos: "n.", ex: "AI governance frameworks are being developed globally." },{ en: "AI regulation", zh: "AIç›£ç®¡", pos: "n.", ex: "Governments are debating AI regulation." },{ en: "digital ethics", zh: "æ•¸ä½å€«ç†", pos: "n.", ex: "Digital ethics guides technology use." },{ en: "consent", zh: "åŒæ„", pos: "n.", ex: "Informed consent is needed for data collection." },{ en: "opt-in", zh: "é¸æ“‡åŠ å…¥", pos: "adj.", ex: "An opt-in system requires user agreement." },{ en: "opt-out", zh: "é¸æ“‡é€€å‡º", pos: "adj.", ex: "Users can opt out of data collection." },{ en: "right to be forgotten", zh: "è¢«éºå¿˜æ¬Š", pos: "n.", ex: "The right to be forgotten is a privacy concept." },{ en: "intellectual property", zh: "æ™ºæ…§è²¡ç”¢", pos: "n.", ex: "AI-generated content raises IP questions." },
    { en: "open source", zh: "é–‹æº", pos: "adj.", ex: "Open source AI models promote collaboration." },{ en: "proprietary", zh: "å°ˆæœ‰çš„", pos: "adj.", ex: "Proprietary models are controlled by companies." },{ en: "adversarial attack", zh: "å°æŠ—æ”»æ“Š", pos: "n.", ex: "Adversarial attacks can fool AI systems." },{ en: "robustness", zh: "ç©©å¥æ€§", pos: "n.", ex: "AI robustness ensures reliable performance." },{ en: "scalability", zh: "å¯æ“´å±•æ€§", pos: "n.", ex: "Scalability is essential for AI deployment." },{ en: "latency", zh: "å»¶é²", pos: "n.", ex: "Low latency is critical for real-time AI." },{ en: "benchmark", zh: "åŸºæº–æ¸¬è©¦", pos: "n.", ex: "AI benchmarks measure model performance." },{ en: "dataset", zh: "è³‡æ–™é›†", pos: "n.", ex: "A diverse dataset reduces bias." },{ en: "annotation", zh: "æ¨™è¨»", pos: "n.", ex: "Data annotation is labor-intensive work." },{ en: "crowdsourcing", zh: "ç¾¤çœ¾å¤–åŒ…", pos: "n.", ex: "Crowdsourcing helps annotate large datasets." },
    { en: "transfer learning", zh: "é·ç§»å­¸ç¿’", pos: "n.", ex: "Transfer learning applies knowledge across tasks." },{ en: "federated learning", zh: "è¯é‚¦å­¸ç¿’", pos: "n.", ex: "Federated learning trains models without sharing data." },{ en: "synthetic data", zh: "åˆæˆè³‡æ–™", pos: "n.", ex: "Synthetic data protects privacy during training." },{ en: "embedding", zh: "åµŒå…¥", pos: "n.", ex: "Word embeddings represent text as numbers." },{ en: "token", zh: "è©å…ƒ", pos: "n.", ex: "Language models process text as tokens." },{ en: "transformer", zh: "è½‰æ›å™¨", pos: "n.", ex: "Transformer architecture revolutionized NLP." },{ en: "attention mechanism", zh: "æ³¨æ„åŠ›æ©Ÿåˆ¶", pos: "n.", ex: "The attention mechanism improves model focus." },{ en: "multimodal", zh: "å¤šæ¨¡æ…‹", pos: "adj.", ex: "Multimodal AI processes text, images, and audio." },{ en: "AI alignment", zh: "AIå°é½Š", pos: "n.", ex: "AI alignment ensures models follow human values." },{ en: "existential risk", zh: "å­˜åœ¨é¢¨éšª", pos: "n.", ex: "Some experts warn of AI existential risk." },
    { en: "precautionary principle", zh: "é é˜²åŸå‰‡", pos: "n.", ex: "The precautionary principle advises caution with new tech." },{ en: "techno-optimism", zh: "ç§‘æŠ€æ¨‚è§€ä¸»ç¾©", pos: "n.", ex: "Techno-optimism believes technology will solve all problems." },{ en: "human-in-the-loop", zh: "äººæ©Ÿå”ä½œ", pos: "n.", ex: "Human-in-the-loop systems keep humans in control." },{ en: "augmented intelligence", zh: "å¢å¼·æ™ºæ…§", pos: "n.", ex: "Augmented intelligence enhances human capabilities." },{ en: "digital divide", zh: "æ•¸ä½è½å·®", pos: "n.", ex: "The digital divide limits AI access in poor regions." },{ en: "democratization", zh: "æ°‘ä¸»åŒ–", pos: "n.", ex: "Democratization of AI gives everyone access to tools." },{ en: "skill gap", zh: "æŠ€èƒ½å·®è·", pos: "n.", ex: "The AI skill gap demands new training programs." },{ en: "reskilling", zh: "é‡æ–°åŸ¹è¨“", pos: "n.", ex: "Reskilling workers is essential in the AI era." },{ en: "upskilling", zh: "æŠ€èƒ½æå‡", pos: "n.", ex: "Upskilling prepares employees for AI-augmented roles." },{ en: "copyright infringement", zh: "ä¾µçŠ¯è‘—ä½œæ¬Š", pos: "n.", ex: "AI-generated art may involve copyright infringement." },
    { en: "plagiarism detection", zh: "æŠ„è¥²åµæ¸¬", pos: "n.", ex: "Plagiarism detection tools use AI." },{ en: "misinformation", zh: "éŒ¯èª¤è³‡è¨Š", pos: "n.", ex: "AI can both create and combat misinformation." },{ en: "disinformation", zh: "è“„æ„æ•£å¸ƒçš„å‡è³‡è¨Š", pos: "n.", ex: "AI-powered disinformation campaigns threaten democracy." },{ en: "filter bubble", zh: "éæ¿¾æ³¡æ³¡", pos: "n.", ex: "Filter bubbles limit exposure to diverse viewpoints." },{ en: "echo chamber", zh: "åŒæº«å±¤", pos: "n.", ex: "Social media algorithms create echo chambers." },{ en: "content moderation", zh: "å…§å®¹å¯©æ ¸", pos: "n.", ex: "AI assists in content moderation on platforms." },{ en: "trustworthy AI", zh: "å¯ä¿¡è³´AI", pos: "n.", ex: "Trustworthy AI systems are fair and transparent." },{ en: "AI literacy", zh: "AIç´ é¤Š", pos: "n.", ex: "AI literacy helps citizens understand technology." },{ en: "computational thinking", zh: "é‹ç®—æ€ç¶­", pos: "n.", ex: "Computational thinking is a key 21st-century skill." },{ en: "ethical hacking", zh: "é“å¾·é§­å®¢", pos: "n.", ex: "Ethical hacking tests system vulnerabilities." },
    { en: "digital footprint", zh: "æ•¸ä½è¶³è·¡", pos: "n.", ex: "Your digital footprint reveals much about you." },{ en: "data sovereignty", zh: "è³‡æ–™ä¸»æ¬Š", pos: "n.", ex: "Data sovereignty determines who controls data." },{ en: "privacy by design", zh: "éš±ç§è¨­è¨ˆ", pos: "n.", ex: "Privacy by design embeds protection in systems." },{ en: "bias mitigation", zh: "åè¦‹ç·©è§£", pos: "n.", ex: "Bias mitigation reduces unfairness in AI." },{ en: "fairness", zh: "å…¬å¹³æ€§", pos: "n.", ex: "Fairness in AI is a major research area." },{ en: "impact assessment", zh: "å½±éŸ¿è©•ä¼°", pos: "n.", ex: "An AI impact assessment evaluates potential harms." },{ en: "stakeholder engagement", zh: "åˆ©å®³é—œä¿‚äººåƒèˆ‡", pos: "n.", ex: "Stakeholder engagement improves AI governance." },{ en: "adjudicate", zh: "è£æ±º", pos: "v.", ex: "The judge adjudicated the dispute." },{ en: "arbitration", zh: "ä»²è£", pos: "n.", ex: "The case went to arbitration." },{ en: "litigation", zh: "è¨´è¨Ÿ", pos: "n.", ex: "Litigation can be very costly." }
  ],
  grammar: [
    { title: "è¢«å‹•èªæ…‹çš„é«˜ç´šè®ŠåŒ–", explain: "åŒ…å« get + p.p., have sth done, è¢«å‹•ä¸å®šè© to be + p.p., è¢«å‹•å‹•åè© being + p.p.ã€‚", examples: ["Many workers got laid off when automation was introduced.", "We should have this data analyzed by the AI system.", "The algorithm is expected to be improved by next year.", "Being monitored constantly by AI raises privacy concerns."], tip: "get + p.p. æ¯” be + p.p. æ›´å£èªï¼Œå¸¸ç”¨æ–¼éæ­£å¼èªå¢ƒã€‚" },
    { title: "è™›ä¸»è© It + è¢«å‹• + that å­å¥", explain: "It is said/believed/estimated/reported that... å¸¸ç”¨æ–¼å­¸è¡“å’Œæ–°èå¯«ä½œã€‚", examples: ["It is estimated that AI will affect 300 million jobs worldwide.", "It is widely believed that AI will surpass human intelligence.", "It has been reported that deepfake technology is advancing rapidly.", "It cannot be denied that AI has transformed healthcare."], tip: "ä¹Ÿå¯ä»¥æ”¹å¯«ç‚ºï¼šAI is estimated to affect... / AI is believed to surpass..." },
    { title: "æ¯”è¼ƒå¥å‹çš„é€²éšç”¨æ³•", explain: "The more... the more..., no sooner...than, not so much A as B, as much A as Bã€‚", examples: ["The more data an AI system processes, the more accurate it becomes.", "No sooner had the technology been released than concerns arose.", "The problem is not so much the technology as the way it is used.", "AI development requires as much ethical consideration as technical skill."], tip: "not so much A as B = èˆ‡å…¶èªªæ˜¯ A ä¸å¦‚èªªæ˜¯ Bã€‚" },
    { title: "åè©ç‰‡èªçš„è¤‡é›œä¿®é£¾", explain: "ç”¨ä»‹ç³»è©ç‰‡èªã€åˆ†è©ç‰‡èªã€é—œä¿‚å­å¥ç­‰ç–ŠåŠ ä¿®é£¾åè©ã€‚", examples: ["The decision-making algorithm used in criminal justice has been criticized.", "AI systems trained on biased data inevitably produce biased results.", "The ethical framework proposed by leading researchers requires revision.", "Regulations governing the use of facial recognition technology vary widely."], tip: "å­¸è¡“å¯«ä½œä¸­ï¼Œåè©å¾Œé¢å¸¸è·Ÿå¤šå±¤ä¿®é£¾èªã€‚" },
  ],
  listening: [
    { text: "A recent study found that an AI system trained to screen job applications was systematically discriminating against women. The algorithm had been trained on historical hiring data, which reflected decades of gender bias. This case illustrates a fundamental challenge: AI systems learn from data, and if the data reflects existing prejudices, the AI will perpetuate and even amplify those biases.", opts: ["The AI deliberately chose to discriminate.", "AI can perpetuate biases present in training data.", "Historical data is always fair."], ans: 1, zh: "é€™å€‹æ¡ˆä¾‹èªªæ˜äº†ä»€éº¼ï¼Ÿ" },
    { text: "The European Union has introduced the AI Act, one of the world's first comprehensive regulations for artificial intelligence. The law classifies AI systems by risk level. High-risk applications, such as those used in healthcare, education, and law enforcement, face strict requirements for transparency, human oversight, and regular auditing. The legislation aims to ensure that AI serves citizens rather than threatens their rights.", opts: ["The EU banned all AI technology.", "The AI Act classifies AI by risk level with varying regulations.", "Only healthcare AI is regulated."], ans: 1, zh: "æ­ç›Ÿçš„ AI æ³•æ¡ˆæœ‰ä»€éº¼ç‰¹é»ï¼Ÿ" },
    { text: "Generative AI tools have created an unprecedented challenge for education. Students can now use AI to write essays, solve math problems, and even generate code. Some educators see this as cheating and want to ban these tools. Others argue that learning to work alongside AI is an essential skill for the future, and that education should adapt to incorporate these tools rather than resist them.", opts: ["All educators want to ban AI.", "There is debate about whether to ban or embrace AI in education.", "AI cannot help with schoolwork."], ans: 1, zh: "æ•™è‚²ç•Œå°ç”Ÿæˆå¼ AI æœ‰ä»€éº¼çœ‹æ³•ï¼Ÿ" },
    { text: "The concept of AI alignment refers to the challenge of ensuring that artificial intelligence systems act in accordance with human values and intentions. As AI becomes more powerful, the risk of misalignment grows. An AI tasked with maximizing a particular metric might find creative but harmful ways to achieve its goal. Researchers in AI safety argue that solving the alignment problem is one of the most important challenges facing humanity.", opts: ["AI alignment is about making AI faster.", "Alignment ensures AI acts according to human values.", "The alignment problem has been solved."], ans: 1, zh: "AI å°é½Šæ˜¯ä»€éº¼ï¼Ÿ" },
    { text: "Self-driving cars present a modern version of the trolley problem. If an autonomous vehicle must choose between two harmful outcomes â€” say, hitting a pedestrian or swerving into a wall and endangering its passengers â€” how should it be programmed to decide? Different cultures give different answers. Research shows that people in collectivist societies tend to favor protecting groups, while those in individualist societies prioritize protecting the individual.", opts: ["Self-driving cars never face ethical dilemmas.", "Cultural values influence how people think autonomous vehicles should decide.", "All cultures agree on how self-driving cars should behave."], ans: 1, zh: "ä¸åŒæ–‡åŒ–å°è‡ªé§•è»Šçš„å€«ç†å•é¡Œæœ‰ä»€éº¼ä¸åŒçœ‹æ³•ï¼Ÿ" },
      { text: "A landmark study has revealed that AI hiring algorithms used by major corporations systematically discriminate against women and minorities. The algorithms, trained on historical data, perpetuate existing biases rather than eliminating them.", opts: ["AI hiring is completely fair.", "AI algorithms can perpetuate hiring discrimination.", "Only humans discriminate in hiring."], ans: 1, zh: "AIæ‹›è˜æ¼”ç®—æ³•æœ‰ä»€éº¼å•é¡Œï¼Ÿ" },
    { text: "The European Union has passed the world's first comprehensive AI regulation, establishing a risk-based framework that bans certain applications like social scoring while imposing strict requirements on high-risk AI systems.", opts: ["The EU has no AI regulations.", "The EU passed comprehensive AI regulation.", "AI regulation is impossible."], ans: 1, zh: "æ­ç›Ÿé€šéäº†ä»€éº¼æ³•æ¡ˆï¼Ÿ" },
    { text: "Deepfake technology has advanced to the point where synthetic video is virtually indistinguishable from authentic footage. Experts warn this could fundamentally undermine trust in visual evidence.", opts: ["Deepfakes are easy to detect.", "Deepfakes could undermine trust in visual evidence.", "Synthetic video is banned worldwide."], ans: 1, zh: "æ·±å½æŠ€è¡“æœ‰ä»€éº¼å½±éŸ¿ï¼Ÿ" },
    { text: "AI researchers are debating whether large language models truly understand language or merely produce statistically plausible responses. This question has profound implications for AI safety.", opts: ["All AI truly understands language.", "Whether AI understands language is debated.", "Language models have human-level intelligence."], ans: 1, zh: "AIç ”ç©¶è€…åœ¨è¾¯è«–ä»€éº¼ï¼Ÿ" },
    { text: "The alignment problem, ensuring that AI systems pursue goals aligned with human values, is considered the most critical challenge in AI development. Misalignment could have catastrophic consequences.", opts: ["AI alignment is not important.", "Alignment is the most critical AI challenge.", "AI systems always share human values."], ans: 1, zh: "å°é½Šå•é¡Œç‚ºä»€éº¼é‡è¦ï¼Ÿ" },
  ],
  reading: [
    {
    passage: "In 2023, the rapid advancement of generative artificial intelligence triggered what many called an 'AI revolution.' Tools capable of producing human-quality text, images, music, and code became widely available, raising profound questions about the future of work, creativity, and truth itself.\n\nThe impact on the workforce has been particularly dramatic. While previous waves of automation primarily affected manual labor, generative AI threatens white-collar jobs that were once considered safe from technological disruption. Copywriters, graphic designers, programmers, and even lawyers are discovering that AI can perform significant portions of their work. McKinsey estimates that up to 30% of work hours could be automated by 2030.\n\nThe creative implications are equally significant. AI can now generate artwork that wins competitions, write poetry that moves readers, and compose music that is virtually indistinguishable from human-created pieces. This raises uncomfortable questions: What is creativity if a machine can replicate it? Does AI-generated art have the same value as human-created art? And who owns the copyright when an AI creates something based on patterns learned from millions of human works?\n\nPerhaps most concerning is AI's potential to undermine truth. Deepfakes â€” hyper-realistic fake videos generated by AI â€” can make anyone appear to say or do anything. Combined with AI-generated text that can produce convincing but entirely fabricated news articles, we face a future where distinguishing fact from fiction becomes exponentially more difficult.\n\nDespite these challenges, many experts argue that the benefits of AI far outweigh the risks. AI has the potential to accelerate scientific discovery, improve healthcare, address climate change, and solve problems that have long seemed intractable. The key, they say, is not to halt progress but to ensure that AI development is guided by strong ethical principles and robust governance frameworks.",
    questions: [
      { q: "What makes the current AI revolution different from previous automation?", opts: ["It only affects factories.", "It threatens white-collar jobs previously safe from disruption.", "It has no impact on employment.", "It only creates new jobs."], ans: 1 },
      { q: "What question does AI-generated art raise?", opts: ["Whether art should be free", "What creativity means if machines can replicate it", "Whether all art should be digital", "Whether museums should close"], ans: 1 },
      { q: "What are deepfakes?", opts: ["Real videos of celebrities", "AI-generated realistic fake videos", "A type of encryption", "A social media platform"], ans: 1 },
      { q: "What percentage of work hours could be automated by 2030?", opts: ["Up to 10%", "Up to 30%", "Up to 70%", "Up to 90%"], ans: 1 },
      { q: "What do experts say is the key to managing AI?", opts: ["Halting all AI development", "Guiding AI with ethics and governance", "Letting the market decide", "Only allowing governments to use AI"], ans: 1 },
    ],
  },
    {
    passage: "The concept of explainable AI has become central to deploying artificial intelligence in high-stakes decision-making. When an AI system denies someone a loan, diagnoses a disease, or recommends a sentence, affected individuals have a right to understand the decision.\n\nMany powerful AI systems, particularly deep neural networks, function as black boxes. They make remarkably accurate predictions, but even their creators cannot fully explain how they arrive at specific conclusions.\n\nThis creates a fundamental tension between accuracy and transparency. Simpler models may be easier to explain but less accurate, while complex models achieving higher accuracy may be essentially opaque.\n\nRegulators are increasingly demanding explainability. The EU's AI Act requires high-risk AI systems to provide meaningful explanations. However, defining what constitutes an adequate explanation remains an open technical and philosophical question.",
    questions: [
      { q: "Why is explainable AI important?", opts: ["For marketing", "People have a right to understand AI decisions", "To make AI faster", "To reduce costs"], ans: 1 },
      { q: "What are black box AI systems?", opts: ["Painted black systems", "Systems whose reasoning cannot be explained", "Very slow systems", "Entertainment systems"], ans: 1 },
      { q: "What tension exists?", opts: ["Speed vs cost", "Accuracy vs transparency", "Size vs portability", "Privacy vs security"], ans: 1 },
      { q: "What does the EU require?", opts: ["All AI banned", "High-risk AI to provide explanations", "Only EU AI used", "AI to replace humans"], ans: 1 },
      { q: "What remains open?", opts: ["Whether AI exists", "What constitutes adequate explanation", "Whether computers calculate", "How to turn AI off"], ans: 1 },
    ],
  },
  ],
  quiz: [
    { s: "AI systems trained on biased data will inevitably _____ those biases.", opts: ["eliminate", "perpetuate", "mitigate", "anonymize"], ans: 1 },
    { s: "It is estimated _____ AI will affect hundreds of millions of jobs.", opts: ["what", "which", "that", "how"], ans: 2 },
    { s: "The more data the model processes, the more _____ it becomes.", opts: ["accurate", "obsolete", "biased", "ubiquitous"], ans: 0 },
    { s: "_____ had the technology been released than privacy concerns arose.", opts: ["Not only", "No sooner", "Hardly", "Neither"], ans: 1 },
    { s: "The problem is not so much the technology _____ the way it is used.", opts: ["than", "but", "as", "or"], ans: 2 },
    { s: "AI _____ occurs when models generate plausible but false information.", opts: ["hallucination","hesitation","habitation","harmonization"], ans: 0 },
    { s: "_____ learning allows AI to improve through trial and error.", opts: ["Reinforced","Reinforcement","Reinforcing","Reinforceable"], ans: 1 },
    { s: "The _____ of AI decisions is crucial for building public trust.", opts: ["explainability","expendability","expandability","exchangeability"], ans: 0 },
    { s: "_____ attacks can trick AI systems by manipulating input data.", opts: ["Advisory","Adversarial","Adversary","Advanced"], ans: 1 },
    { s: "Training large language models requires enormous _____ resources.", opts: ["communicational","computational","compositional","conversational"], ans: 1 },
      { s: "The algorithm exhibited significant ___ against certain demographic groups.", opts: ["bias", "balance", "benefit", "basis"], ans: 0 },
    { s: "Autonomous systems must be designed with robust safety ___.", opts: ["mechanisms", "metaphors", "memories", "mandates"], ans: 0 },
    { s: "The ___ of AI in criminal sentencing raises ethical questions.", opts: ["deployment", "departure", "depression", "derivation"], ans: 0 },
    { s: "Machine learning models require vast amounts of ___ data.", opts: ["labeled", "limited", "literal", "lateral"], ans: 0 },
    { s: "The company failed to ___ the consequences of deploying untested AI.", opts: ["anticipate", "appreciate", "approximate", "accommodate"], ans: 0 },
  ],
};
