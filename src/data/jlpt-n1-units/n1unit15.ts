import type { JlptUnit } from "../jlpt-types";

export const n1unit15: JlptUnit = {
  id: 15,
  title: "技術倫理與AI",
  titleJa: "技術倫理とAI",
  icon: "🤖",
  color: "#dc2626",
  vocab: [
    { ja: "技術倫理", reading: "ぎじゅつりんり", zh: "技術倫理", pos: "名", ex: "技術倫理の確立なくして、技術の健全な発展はあり得ない。", exZh: "沒有技術倫理的確立，就不可能有技術的健全發展。" },
    { ja: "人工知能", reading: "じんこうちのう", zh: "人工智慧", pos: "名", ex: "人工知能の能力が人間を凌駕する日は近いとされている。", exZh: "人工智慧的能力超越人類的日子據說已經不遠了。" },
    { ja: "機械学習", reading: "きかいがくしゅう", zh: "機器學習", pos: "名", ex: "機械学習により、膨大なデータからパターンを抽出できる。", exZh: "透過機器學習，可以從龐大的數據中提取模式。" },
    { ja: "深層学習", reading: "しんそうがくしゅう", zh: "深度學習", pos: "名", ex: "深層学習が画像認識の精度を飛躍的に向上させた。", exZh: "深度學習使圖像辨識的精度飛躍性地提升。" },
    { ja: "アルゴリズム", reading: "アルゴリズム", zh: "演算法", pos: "名", ex: "アルゴリズムの設計者の偏見がシステムに反映されることがある。", exZh: "演算法設計者的偏見有時會反映在系統中。" },
    { ja: "バイアス", reading: "バイアス", zh: "偏差", pos: "名", ex: "AIのバイアスを排除するための研究が進められている。", exZh: "消除AI偏差的研究正在推進。" },
    { ja: "公平性", reading: "こうへいせい", zh: "公平性", pos: "名", ex: "AIの判断における公平性の担保が喫緊の課題だ。", exZh: "保障AI判斷中的公平性是迫切的課題。" },
    { ja: "透明性", reading: "とうめいせい", zh: "透明性", pos: "名", ex: "アルゴリズムの透明性を確保することが求められている。", exZh: "確保演算法的透明性是被要求的。" },
    { ja: "説明可能性", reading: "せつめいかのうせい", zh: "可解釋性", pos: "名", ex: "AIの説明可能性は信頼構築において不可欠だ。", exZh: "AI的可解釋性在建立信任方面不可或缺。" },
    { ja: "自律性", reading: "じりつせい", zh: "自律性", pos: "名", ex: "AIの自律性が高まるほど、倫理的な問題も増大する。", exZh: "AI的自律性越提高，倫理問題也越增大。" },
    { ja: "責任", reading: "せきにん", zh: "責任", pos: "名", ex: "AIが引き起こした事故の責任は誰が負うべきか。", exZh: "AI造成的事故責任應該由誰承擔？" },
    { ja: "帰責", reading: "きせき", zh: "歸責", pos: "名", ex: "自律型システムの帰責の所在が議論されている。", exZh: "自律型系統的歸責所在正在被討論。" },
    { ja: "プライバシー", reading: "プライバシー", zh: "隱私", pos: "名", ex: "顔認証技術の普及がプライバシーを脅かしている。", exZh: "人臉辨識技術的普及正在威脅隱私。" },
    { ja: "監視", reading: "かんし", zh: "監控", pos: "名", ex: "AIによる監視が市民の自由を侵害する懸念がある。", exZh: "有人擔憂AI的監控會侵害市民的自由。" },
    { ja: "データ倫理", reading: "データりんり", zh: "數據倫理", pos: "名", ex: "データ倫理を無視した開発は社会的信用を失墜させる。", exZh: "無視數據倫理的開發會使社會信用喪失。" },
    { ja: "情報倫理", reading: "じょうほうりんり", zh: "資訊倫理", pos: "名", ex: "情報倫理の教育が学校カリキュラムに組み込まれつつある。", exZh: "資訊倫理的教育正在被納入學校課程。" },
    { ja: "自動化", reading: "じどうか", zh: "自動化", pos: "名", ex: "自動化の進展が労働市場に甚大な影響を及ぼしている。", exZh: "自動化的進展對勞動市場造成了巨大影響。" },
    { ja: "失業", reading: "しつぎょう", zh: "失業", pos: "名", ex: "AI導入に伴う失業問題は看過できない。", exZh: "伴隨AI導入的失業問題不容忽視。" },
    { ja: "労働置換", reading: "ろうどうちかん", zh: "勞動替代", pos: "名", ex: "労働置換のリスクは単純作業に留まらない。", exZh: "勞動替代的風險不僅限於簡單作業。" },
    { ja: "ロボット倫理", reading: "ロボットりんり", zh: "機器人倫理", pos: "名", ex: "ロボット倫理は工学と哲学の学際的領域である。", exZh: "機器人倫理是工學與哲學的跨學科領域。" },
    { ja: "自律型兵器", reading: "じりつがたへいき", zh: "自律型武器", pos: "名", ex: "自律型兵器の開発禁止を求める国際的な運動が広がっている。", exZh: "要求禁止開發自律型武器的國際運動正在擴大。" },
    { ja: "キラーロボット", reading: "キラーロボット", zh: "殺手機器人", pos: "名", ex: "キラーロボットの是非をめぐる議論が国連で行われた。", exZh: "圍繞殺手機器人是非的討論在聯合國進行了。" },
    { ja: "フェイクディープ", reading: "フェイクディープ", zh: "深偽技術", pos: "名", ex: "フェイクディープによる偽動画が民主主義を脅かしている。", exZh: "深偽技術製作的假影片正在威脅民主主義。" },
    { ja: "生成AI", reading: "せいせいエーアイ", zh: "生成式AI", pos: "名", ex: "生成AIの登場が創作活動のあり方を根底から覆した。", exZh: "生成式AI的出現從根本上顛覆了創作活動的形態。" },
    { ja: "著作権", reading: "ちょさくけん", zh: "著作權", pos: "名", ex: "生成AIと著作権の関係は法的に未整備な部分が多い。", exZh: "生成式AI與著作權的關係在法律上有很多未整備之處。" },
    { ja: "知的財産", reading: "ちてきざいさん", zh: "智慧財產", pos: "名", ex: "AI生成物の知的財産権の帰属が争点となっている。", exZh: "AI生成物的智慧財產權歸屬成為爭議點。" },
    { ja: "オープンソース", reading: "オープンソース", zh: "開源", pos: "名", ex: "AIのオープンソース化は技術の民主化に寄与する。", exZh: "AI的開源化有助於技術的民主化。" },
    { ja: "デジタル格差", reading: "デジタルかくさ", zh: "數位落差", pos: "名", ex: "デジタル格差の是正は社会正義の観点からも重要だ。", exZh: "糾正數位落差從社會正義的觀點來看也很重要。" },
    { ja: "技術的特異点", reading: "ぎじゅつてきとくいてん", zh: "技術奇異點", pos: "名", ex: "技術的特異点の到来を楽観視するのは早計である。", exZh: "樂觀看待技術奇異點的到來為時過早。" },
    { ja: "人間拡張", reading: "にんげんかくちょう", zh: "人體擴展", pos: "名", ex: "人間拡張技術は障害者の生活の質を飛躍的に向上させうる。", exZh: "人體擴展技術可以大幅提升障礙者的生活品質。" },
    { ja: "トランスヒューマニズム", reading: "トランスヒューマニズム", zh: "超人類主義", pos: "名", ex: "トランスヒューマニズムの是非をめぐって哲学者の間で論争が続いている。", exZh: "圍繞超人類主義的是非，哲學家之間的論爭仍在持續。" },
    { ja: "サイボーグ", reading: "サイボーグ", zh: "賽博格", pos: "名", ex: "義肢の進化により、サイボーグ技術は現実のものとなりつつある。", exZh: "隨著義肢的進化，賽博格技術正在成為現實。" },
    { ja: "脳科学", reading: "のうかがく", zh: "腦科學", pos: "名", ex: "脳科学の知見がAI研究にフィードバックされている。", exZh: "腦科學的知識正在被回饋到AI研究中。" },
    { ja: "ブレインマシンインターフェース", reading: "ブレインマシンインターフェース", zh: "腦機介面", pos: "名", ex: "ブレインマシンインターフェースが思考だけで機器を操作する可能性を開いた。", exZh: "腦機介面開啟了僅憑思考就能操作設備的可能性。" },
    { ja: "意識", reading: "いしき", zh: "意識", pos: "名", ex: "AIに意識が宿りうるかは哲学上の重大な問いである。", exZh: "AI是否能擁有意識是哲學上的重大問題。" },
    { ja: "人格", reading: "じんかく", zh: "人格", pos: "名", ex: "AIに人格を認めるべきかという議論が浮上している。", exZh: "是否應該承認AI的人格這一討論正在浮出水面。" },
    { ja: "道徳的地位", reading: "どうとくてきちい", zh: "道德地位", pos: "名", ex: "高度なAIに道徳的地位を付与すべきかが問われている。", exZh: "是否應該賦予高度AI道德地位正在被質疑。" },
    { ja: "功利主義", reading: "こうりしゅぎ", zh: "功利主義", pos: "名", ex: "功利主義の観点からは最大多数の幸福を追求する。", exZh: "從功利主義的觀點追求最大多數人的幸福。" },
    { ja: "義務論", reading: "ぎむろん", zh: "義務論", pos: "名", ex: "義務論の立場では行為そのものの道徳性が問われる。", exZh: "從義務論的立場質疑行為本身的道德性。" },
    { ja: "徳倫理", reading: "とくりんり", zh: "德性倫理", pos: "名", ex: "徳倫理は行為者の品性や徳を重視する倫理学の立場だ。", exZh: "德性倫理是重視行為者品性和德行的倫理學立場。" },
    { ja: "技術決定論", reading: "ぎじゅつけっていろん", zh: "技術決定論", pos: "名", ex: "技術決定論は技術が社会変革の主要因だと主張する。", exZh: "技術決定論主張技術是社會變革的主要因素。" },
    { ja: "社会構成主義", reading: "しゃかいこうせいしゅぎ", zh: "社會建構主義", pos: "名", ex: "社会構成主義の視点からは技術もまた社会的に構築される。", exZh: "從社會建構主義的視角來看，技術也是被社會建構的。" },
    { ja: "リスク評価", reading: "リスクひょうか", zh: "風險評估", pos: "名", ex: "新技術のリスク評価を事前に行うことが肝要だ。", exZh: "事前進行新技術的風險評估至關重要。" },
    { ja: "予防原則", reading: "よぼうげんそく", zh: "預防原則", pos: "名", ex: "予防原則に基づき、不確実なリスクにも慎重に対処すべきだ。", exZh: "基於預防原則，對不確定的風險也應謹慎應對。" },
    { ja: "技術評価", reading: "ぎじゅつひょうか", zh: "技術評估", pos: "名", ex: "議会による技術評価が政策決定に不可欠だ。", exZh: "議會的技術評估對政策決定不可或缺。" },
    { ja: "規制", reading: "きせい", zh: "規制", pos: "名", ex: "AIの規制は技術革新を阻害しない範囲で行うべきだ。", exZh: "AI的規制應在不阻礙技術革新的範圍內進行。" },
    { ja: "ガバナンス", reading: "ガバナンス", zh: "治理", pos: "名", ex: "AIガバナンスの国際的な枠組みの構築が急がれている。", exZh: "建構AI治理的國際框架刻不容緩。" },
    { ja: "イノベーション", reading: "イノベーション", zh: "創新", pos: "名", ex: "倫理を無視したイノベーションは社会に禍根を残す。", exZh: "無視倫理的創新會給社會留下禍根。" },
    { ja: "持続可能性", reading: "じぞくかのうせい", zh: "永續性", pos: "名", ex: "技術開発においても持続可能性の視点が不可欠だ。", exZh: "在技術開發中永續性的視角也不可或缺。" },
    { ja: "共生", reading: "きょうせい", zh: "共生", pos: "名", ex: "人間とAIの共生のあり方を真摯に模索すべき時代だ。", exZh: "這是一個應該認真探索人類與AI共生方式的時代。" },
  ],
  grammar: [
    {
      title: "～たりとも～ない",
      explain: "表示「即使一…也不…」，強調連最小的量都不允許。接數量詞＋たりとも。",
      examples: [
        "個人データは一件たりとも漏洩させてはならない。",
        "AIの判断ミスは一度たりとも許されない領域がある。",
        "技術倫理の原則は一つたりとも軽視すべきではない。",
        "一瞬たりとも油断すれば、サイバー攻撃の標的になりかねない。"
      ],
      examplesZh: [
        "即使一件個人數據也不能洩漏。",
        "有些領域即使一次AI判斷失誤也不被允許。",
        "技術倫理的原則即使一個也不應該輕視。",
        "即使一瞬間的疏忽，也可能成為網路攻擊的目標。"
      ],
      tip: "前面常接「一＋量詞」，強調「連這麼少的量都不行」的語氣。"
    },
    {
      title: "～をものともせず",
      explain: "表示「不畏…」「不在乎…」，面對困難或障礙毫不退縮。接名詞。",
      examples: [
        "批判をものともせず、研究者はAI倫理の研究を続けた。",
        "技術的困難をものともせず、開発チームは挑戦を続けている。",
        "既存の常識をものともせず、新しいパラダイムを提唱した。",
        "業界の反発をものともせず、政府はAI規制法を推進した。"
      ],
      examplesZh: [
        "不畏批評，研究者繼續了AI倫理的研究。",
        "不畏技術困難，開發團隊持續挑戰。",
        "不在乎既有的常識，提出了新的典範。",
        "不在乎業界的反對，政府推進了AI規制法。"
      ],
      tip: "用於褒義場合，讚揚某人不畏困難的勇氣和毅力。"
    },
    {
      title: "～が最後",
      explain: "表示「一旦…就（會有不好的結果）」，強調一旦發生就無法挽回。接動詞た形。",
      examples: [
        "個人情報が流出したが最後、完全に回収することは不可能だ。",
        "自律型兵器が実戦投入されたが最後、歯止めがきかなくなる。",
        "AIにすべてを委ねたが最後、人間の判断力は退化するだろう。",
        "フェイクディープが拡散したが最後、真偽の判別は極めて困難になる。"
      ],
      examplesZh: [
        "個人資訊一旦洩漏，就不可能完全回收。",
        "自律型武器一旦投入實戰，就會無法控制。",
        "一旦把一切委託給AI，人類的判斷力就會退化吧。",
        "深偽影片一旦擴散，真偽的辨別就會變得極其困難。"
      ],
      tip: "帶有強烈的警告語氣，常用於指出不可逆轉的嚴重後果。"
    },
    {
      title: "～まじき",
      explain: "表示「不該…的」「不可…的」，強烈的否定評價。接名詞＋に＋あるまじき或動詞辭書形＋まじき。",
      examples: [
        "利用者のプライバシーを侵害するのは技術者にあるまじき行為だ。",
        "データを改ざんするとは、研究者にあるまじきことだ。",
        "倫理を無視した開発は、企業にあるまじき姿勢である。",
        "許すまじき人権侵害がAI監視システムによって行われている。"
      ],
      examplesZh: [
        "侵害使用者隱私是技術人員不該有的行為。",
        "竟然篡改數據，這是研究者不該做的事。",
        "無視倫理的開發是企業不該有的態度。",
        "不可饒恕的人權侵害正透過AI監控系統被執行。"
      ],
      tip: "「～にあるまじき」表示「不配作為…」，語氣非常強烈。"
    },
    {
      title: "～んがため",
      explain: "表示「為了…」，比「ために」更書面、更強烈的目的表現。接動詞未然形（ない形去ない）＋んがため。",
      examples: [
        "技術の健全な発展を促さんがため、倫理指針が策定された。",
        "AIの暴走を防がんがため、安全装置の研究が進められている。",
        "公平性を確保せんがため、アルゴリズムの監査制度が導入された。",
        "人間の尊厳を守らんがため、技術倫理の議論は不可欠だ。"
      ],
      examplesZh: [
        "為了促進技術的健全發展，制定了倫理指南。",
        "為了防止AI暴走，安全裝置的研究正在推進。",
        "為了確保公平性，導入了演算法的監查制度。",
        "為了守護人的尊嚴，技術倫理的討論不可或缺。"
      ],
      tip: "非常書面的古典表現。する→せんがため、防ぐ→防がんがため。"
    }
  ],
  listening: [
    { text: "AI倫理学者が講演で、AIの判断にバイアスが生じる原因について説明しています。最も根本的な原因として挙げているのは何ですか。", opts: ["AIの計算能力の限界", "学習データに含まれる社会的偏見", "プログラマーの技術不足", "ハードウェアの性能不足"], ans: 1, zh: "AI倫理學者在演講中說明AI判斷產生偏差的原因。他認為最根本的原因是什麼？" },
    { text: "国際会議で自律型兵器の規制について議論されています。規制推進派が主張している最も重要な論点は何ですか。", opts: ["開発コストの削減", "殺傷の判断を機械に委ねることの倫理的問題", "兵器の技術的な不安定さ", "国際競争力の低下"], ans: 1, zh: "國際會議上正在討論自律型武器的規制。規制推進派主張的最重要論點是什麼？" },
    { text: "テレビの報道番組で生成AIと著作権の問題を取り上げています。法律の専門家は現状をどう評価していますか。", opts: ["完全に法整備が済んでいる", "法律が技術の進歩に追いついていない", "著作権は不要になる", "既存の法律で十分対応できる"], ans: 1, zh: "電視新聞節目討論了生成式AI和著作權的問題。法律專家如何評價現狀？" },
    { text: "大学院のゼミでAIの説明可能性について発表が行われています。説明可能性が特に重要な分野として挙げられているのはどれですか。", opts: ["ゲーム開発", "医療診断と司法判断", "天気予報", "音楽生成"], ans: 1, zh: "研究所的研討會上進行了關於AI可解釋性的發表。被舉出特別需要可解釋性的領域是哪個？" },
    { text: "哲学者がシンポジウムでAIの意識について論じています。AIに意識があるかを判定する上での最大の困難は何だと述べていますか。", opts: ["AIの処理速度が遅すぎること", "意識そのものの定義が確立していないこと", "AIが嘘をつくこと", "実験環境が整っていないこと"], ans: 1, zh: "哲學家在研討會上討論AI的意識。他認為判定AI是否有意識的最大困難是什麼？" },
    { text: "企業のCTOがAIガバナンスについてインタビューに答えています。企業がまず取り組むべきこととして述べているのは何ですか。", opts: ["AIの開発速度を上げること", "社内にAI倫理委員会を設置すること", "すべてのAIプロジェクトを中止すること", "政府の規制を待つこと"], ans: 1, zh: "企業的CTO接受AI治理的訪問。他認為企業首先應該著手的是什麼？" },
    { text: "ドキュメンタリー番組でフェイクディープの脅威について特集しています。最も深刻な影響として指摘されているのは何ですか。", opts: ["エンターテインメント産業の衰退", "選挙や民主主義プロセスへの干渉", "SNSの利用者減少", "映画産業の技術革新の停滞"], ans: 1, zh: "紀錄片節目特集了深偽技術的威脅。被指出最嚴重的影響是什麼？" },
    { text: "脳科学者がブレインマシンインターフェースの最新研究について報告しています。実用化に向けた倫理的課題として挙げているのは何ですか。", opts: ["装置が高額すぎること", "脳データのプライバシー保護と思考の自由の確保", "手術のリスクが高いこと", "効果が不安定なこと"], ans: 1, zh: "腦科學家報告了腦機介面的最新研究。他舉出實用化的倫理課題是什麼？" },
    { text: "社会学者がデジタル格差の問題について分析しています。格差が拡大している根本的な構造的要因は何だと述べていますか。", opts: ["個人の努力不足", "既存の社会的・経済的不平等がデジタル領域に再生産されること", "技術の進歩が遅すぎること", "政府の介入が多すぎること"], ans: 1, zh: "社會學家分析了數位落差的問題。他認為落差擴大的根本結構性因素是什麼？" },
    { text: "AI開発者のパネルディスカッションで、責任あるAI開発について議論しています。登壇者たちが共通して最も重視しているのは何ですか。", opts: ["開発速度の最大化", "利益の最大化", "人間中心の設計思想の堅持", "規制の最小化"], ans: 2, zh: "AI開發者的座談會上討論了負責任的AI開發。座談者們共同最重視的是什麼？" },
  ],
  reading: [
    {
      passage: "人工知能の急速な発展に伴い、「AIに意識はあるか」という哲学的問いが現実味を帯びてきた。大規模言語モデルの出現により、AIは人間と見紛うほど自然な対話を生成できるようになったが、それは真の理解や意識の存在を意味するのだろうか。哲学者ジョン・サールが提唱した「中国語の部屋」の思考実験は、シンボルの操作と理解は本質的に異なることを示唆した。しかし、意識の定義そのものが科学的に確立していない現状では、AIに意識があるかないかを客観的に判定する基準は存在しない。仮にAIが意識を持つとすれば、その道徳的地位をどう扱うべきかという新たな倫理的問題が生じる。逆に、意識がないにもかかわらず人間がAIに感情移入してしまう現象も、社会的な影響を及ぼしうる。AIと人間の境界が曖昧になりつつある今、技術倫理の枠組みを根本から再構築する必要がある。",
      questions: [
        { q: "「中国語の部屋」の思考実験が示唆していることは何か。", opts: ["AIは中国語を理解できないこと", "シンボルの操作と理解は本質的に異なること", "AIには意識があること", "中国語は学習が困難であること"], ans: 1 },
        { q: "本文の主張として最も適切なものはどれか。", opts: ["AIには明らかに意識がある", "AIの意識の有無は既に科学的に解決済みである", "AIと人間の境界が曖昧になる中で技術倫理の再構築が必要", "AIへの感情移入は社会的に問題がない"], ans: 2 }
      ]
    },
    {
      passage: "生成AIの登場は、著作権制度の根幹を揺るがす問題を突きつけている。従来の著作権法は人間の創作活動を保護することを前提としているが、AIが生成したコンテンツの権利の帰属は法的に明確ではない。学習データに含まれる既存の著作物との関係も複雑だ。AIが大量の著作物を学習し、それを基に新たなコンテンツを生成する過程が「引用」や「変形」に当たるのか、それとも「複製」に該当するのかは、国によって判断が分かれている。クリエイターの間では、自らの作品が無断でAIの学習に使われることへの懸念が高まっている。一方で、AIによる創作の可能性を狭めすぎることは、イノベーションの阻害につながるという主張もある。技術と権利のバランスをいかに図るかが、各国の立法者に問われている喫緊の課題である。",
      questions: [
        { q: "生成AIが著作権制度に問題を突きつけている理由として、本文で述べられているのはどれか。", opts: ["AIが著作権を主張し始めたから", "従来の著作権法が人間の創作を前提としており、AI生成物の権利が不明確だから", "AIが著作物を全く利用しないから", "著作権制度自体が廃止されつつあるから"], ans: 1 },
        { q: "本文で述べられているAI規制に関する対立点はどれか。", opts: ["AIの開発を全面禁止すべきか否か", "クリエイターの権利保護とイノベーション促進のバランス", "先進国と途上国のどちらが主導すべきか", "AIの学習データを全て公開すべきか否か"], ans: 1 }
      ]
    }
  ],
  quiz: [
    { s: "個人データは一件（　）漏洩させてはならない。", opts: ["たりとも", "だけでも", "ばかりも", "ほども"], ans: 0 },
    { s: "批判を（　）、研究者はAI倫理の研究を続けた。", opts: ["ものともせず", "ものとして", "ものにせず", "ものだから"], ans: 0 },
    { s: "個人情報が流出した（　）、完全に回収することは不可能だ。", opts: ["が最後", "が最初", "が結果", "が原因"], ans: 0 },
    { s: "データを改ざんするとは、研究者に（　）ことだ。", opts: ["あるまじき", "あるべき", "あるらしき", "あるがごとき"], ans: 0 },
    { s: "技術の健全な発展を促さ（　）、倫理指針が策定された。", opts: ["んがため", "んばかり", "んとして", "んがごとく"], ans: 0 },
    { s: "AIの判断における（　）の担保が喫緊の課題だ。", opts: ["公平性", "平等性", "均等性", "同等性"], ans: 0 },
    { s: "アルゴリズムの（　）を確保することが求められている。", opts: ["透明性", "流動性", "弾力性", "柔軟性"], ans: 0 },
    { s: "AIが引き起こした事故の（　）は誰が負うべきか。", opts: ["責任", "義務", "権利", "任務"], ans: 0 },
    { s: "（　）原則に基づき、不確実なリスクにも慎重に対処すべきだ。", opts: ["予防", "予測", "予想", "予定"], ans: 0 },
    { s: "倫理を無視した（　）は社会に禍根を残す。", opts: ["イノベーション", "インフレーション", "イルミネーション", "イミグレーション"], ans: 0 },
  ]
};
